<!DOCTYPE html>
<html lang="pt-br">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

  	<meta property="og:title" content=" Compilação do Hadoop para CentOS6 / RHEL6 usando Docker &middot;  Grandes Dados" />
  	<meta property="og:site_name" content="Grandes Dados" />
  	<meta property="og:url" content="http://grandesdados.com/post/compilacao-do-hadoop-para-centos6-rhel6-usando-docker/" />
    <meta property="og:image" content="images/placeholder-share.jpg" />

    
  	<meta property="og:type" content="article" />

    <meta property="og:article:published_time" content="2015-08-31T22:45:23-03:00" />

    
    <meta property="og:article:tag" content="Tutorial" />
    
    <meta property="og:article:tag" content="Hadoop" />
    
    <meta property="og:article:tag" content="Docker" />
    
    <meta property="og:article:tag" content="CentOS6" />
    
    <meta property="og:article:tag" content="RHEL6" />
    
    

  <title>
     Compilação do Hadoop para CentOS6 / RHEL6 usando Docker &middot;  Grandes Dados
  </title>

    <meta name="description" content="Blog de BigData" />

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="http://grandesdados.com/images/favicon.ico">
	  <link rel="apple-touch-icon" href="http://grandesdados.com/images/apple-touch-icon.png" />

    <link rel="stylesheet" type="text/css" href="http://grandesdados.com/css/screen.css" />
    <link rel="stylesheet" type="text/css" href="http://grandesdados.com/css/nav.css" />
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400|Inconsolata" />


    
      
          <link href="http://grandesdados.com/index.xml" rel="alternate" type="application/rss+xml" title="Grandes Dados" />
      
      
    
    <meta name="generator" content="Hugo 0.14" />

    <link rel="canonical" href="http://grandesdados.com/post/compilacao-do-hadoop-para-centos6-rhel6-usando-docker/" />

    
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-38960920-6', 'auto');
      ga('send', 'pageview');

    </script>
    

    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/styles/solarized_dark.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

</head>
<body class="nav-closed">

  <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
        
        
        
            
            <li class="nav-opened" role="presentation">
            	<a href="http://grandesdados.com/">Blog</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="https://github.com/GrandesDados">GitHub</a>
            </li>
        
    </ul>
    
    
    <a class="subscribe-button icon-feed" href="http://grandesdados.com/index.xml">Subscribe</a>
    
</div>
<span class="nav-cover"></span>


 <div class="site-wrapper">




<header class="main-header post-head no-cover">
  <nav class="main-nav clearfix">


  
  
      <a class="menu-button" href="#"><span class="burger">&#9776;</span><span class="word">Menu</span></a>
  
  </nav>
</header>



<main class="content" role="main">




  <article class="post post">

    <header class="post-header">
        <h1 class="post-title">Compilação do Hadoop para CentOS6 / RHEL6 usando Docker</h1>
        <small></small>

        <section class="post-meta">
        
          <time class="post-date" datetime="2015-08-31T22:45:23-03:00">
            Aug 31, 2015
          </time>
        
         
          <span class="post-tag small"><a href="http://grandesdados.com/tags/tutorial/">#Tutorial</a></span>
         
          <span class="post-tag small"><a href="http://grandesdados.com/tags/hadoop/">#Hadoop</a></span>
         
          <span class="post-tag small"><a href="http://grandesdados.com/tags/docker/">#Docker</a></span>
         
          <span class="post-tag small"><a href="http://grandesdados.com/tags/centos6/">#CentOS6</a></span>
         
          <span class="post-tag small"><a href="http://grandesdados.com/tags/rhel6/">#RHEL6</a></span>
         
        </section>
    </header>
  
    <section class="post-content">
      

<p>Esse tutorial é sobre a construção do pacote do Hadoop 2.7.1 para o CentOS6 / RHEL6 usando Docker. Esse procedimento é necessário para gerar as bibliotecas nativas compatíveis. O principal objetivo que motivou esse trabalho foi configurar o FairScheduler do YARN usando CGroups rodando no Red Hat Enterprise Linux 6 (RHEL6). O pacote Hadoop distribuído pela Apache tem executável binário que não é compatível com a Glibc que faz parte do CentOS6/RHEL6.</p>

<p>O RHEL6 é o sistema operacional homologado para as máquinas do cluster que usamos na Globo.com e foi necessário criar uma distribuição própria do Hadoop para que pudéssemos fazer uso do <a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/FairScheduler.html">FairScheduler</a> juntamente com o <a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/NodeManagerCgroups.html">CGroups</a> para limitar o uso de processamento entre as aplicações rodando nos mesmos NodeManagers.</p>

<p>Esse trabalho de configuração do Hadoop para uso compartilhado será assunto de outro artigo.</p>

<p>Nesse artigo, o foco é um passo a passo de como usar o Docker para gerar um pacote do Hadoop adaptado para o Red Hat Enterprise Linux 6 (RHEL6) usando CentOS6.</p>

<h2 id="pré-requisito:ac8d87b01c866329a85ac2f7311bc677">Pré-requisito</h2>

<p>Nesse procedimento, é necessário que o Docker esteja instalado e funcionando; também é necessário acesso à Internet.</p>

<p>Originalmente, esse procedimento foi testado no ArchLinux atualizado até final de Agosto/2015.</p>

<p><a href="https://wiki.archlinux.org/index.php/Docker">https://wiki.archlinux.org/index.php/Docker</a></p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">sudo docker version

&gt; Client:
&gt;  Version:      1.8.1
&gt;  API version:  1.20
&gt;  Go version:   go1.4.2
&gt;  Git commit:   d12ea79
&gt;  Built:        Sat Aug 15 17:29:10 UTC 2015
&gt;  OS/Arch:      linux/amd64
&gt;
&gt; Server:
&gt;  Version:      1.8.1
&gt;  API version:  1.20
&gt;  Go version:   go1.4.2
&gt;  Git commit:   d12ea79
&gt;  Built:        Sat Aug 15 17:29:10 UTC 2015
&gt;  OS/Arch:      linux/amd64</code></pre>
</p>

<h2 id="compilação:ac8d87b01c866329a85ac2f7311bc677">Compilação</h2>

<p>Documento com instruções de build do Hadoop <a href="https://github.com/apache/hadoop/blob/release-2.7.1/BUILDING.txt">aqui</a>.</p>

<p>O resultado desse procedimento é um pacote do Hadoop com os executáveis e bibliotecas nativas compilados para o CentOS6 que rodam no RHEL6.</p>

<p><code>/hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz</code></p>

<p>&hellip;</p>

<p>Começamos com a criação de um conainer do Docker com a imagem do CentOS6.</p>

<p>Ao executar o comando <code>run</code>, o Docker automaticamente fará o download da imagem e a shell será inicializada dentro de um novo container.</p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">sudo docker run -i -t centos:6 /bin/bash

&gt; Unable to find image &#39;centos:6&#39; locally
&gt; 6: Pulling from library/centos
&gt;
&gt; f1b10cd84249: Pull complete
&gt; fb9cc58bde0c: Pull complete
&gt; a005304e4e74: Already exists
&gt; library/centos:6: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security.
&gt;
&gt; Digest: sha256:25d94c55b37cb7a33ad706d5f440e36376fec20f59e57d16fe02c64698b531c1
&gt; Status: Downloaded newer image for centos:6
&gt; [root@3cc2bc5e593b /]#</code></pre>
</p>

<p>Já dentro do container criamos um usuário e local que serão usados na compilação e geração do pacote.</p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">adduser -m -d /hadoop hadoop
cd hadoop</code></pre>
</p>

<p>Para a compilação das bibliotecas nativas é necessária a instalação do compilador C e mais alguns pacotes de desenvolvimento (cabeçalhos das bibliotecas usadas pelo Hadoop).</p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">yum install -y tar gzip gcc-c&#43;&#43; cmake zlib zlib-devel openssl openssl-devel fuse fuse-devel bzip2 bzip2-devel snappy snappy-devel

&gt; (...)</code></pre>
</p>

<p>O Hadoop ainda depende de duas outras bibliotecas que precisam ser instaladas manualmente no CentOS: Google ProtoBuf 2.5 (RPC), Jansson (JSON).</p>

<p>Para instalar o ProtoBuf, é necessário baixar o pacote, configurar para as pastas do CentOS (64 bits) e instalar.</p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">curl -L -O https://github.com/google/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz
tar zxf protobuf-2.5.0.tar.gz
cd protobuf-2.5.0
./configure --prefix=/usr --libdir=/usr/lib64
make
make check
make install

cd ..</code></pre>
</p>

<p>Para instalar o Jansson, é necessário baixar o pacote, configurar para as pastas do CentOS (64 bits) e instalar.</p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">curl -O http://www.digip.org/jansson/releases/jansson-2.7.tar.gz
tar zxf jansson-2.7.tar.gz
cd jansson-2.7
./configure --prefix=/usr --libdir=/usr/lib64
make
make install

cd ..</code></pre>
</p>

<p>Para completar o ambiente de compilação, precisamos do JDK e do Maven.</p>

<p>No caso do JDK, usaremos o pacote RPM já disponibilizado pela Oracle.</p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">curl -k -L -H &#34;Cookie: oraclelicense=accept-securebackup-cookie&#34; -O http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.rpm
rpm -i jdk-8u60-linux-x64.rpm</code></pre>
</p>

<p>No caso do Maven, usaremos o pacote binário de distribuição da Apache.</p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">curl -O http://archive.apache.org/dist/maven/maven-3/3.3.3/binaries/apache-maven-3.3.3-bin.tar.gz
tar zxf apache-maven-3.3.3-bin.tar.gz</code></pre>
</p>

<p>O ambiente  de compilação está completo.</p>

<p>Agora estamos pronto para a compilação do Hadoop. Nesse caso, estaremos gerando o pacote de distribuição somente com o binário Java e as bibliotecas nativas.</p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">su - hadoop

export PATH=$PATH:/hadoop/apache-maven-3.3.3/bin

curl -O http://archive.apache.org/dist/hadoop/common/hadoop-2.7.1/hadoop-2.7.1-src.tar.gz
tar zxf hadoop-2.7.1-src.tar.gz
cd hadoop-2.7.1-src

mvn clean package -Pdist,native -DskipTests -Drequire.snappy -Drequire.openssl -Dtar

&gt; (...)
&gt; main:
&gt;      [exec] $ tar cf hadoop-2.7.1.tar hadoop-2.7.1
&gt;      [exec] $ gzip -f hadoop-2.7.1.tar
&gt;      [exec]
&gt;      [exec] Hadoop dist tar available at: /hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz
&gt;      [exec]
&gt; [INFO] Executed tasks
&gt; [INFO]
&gt; [INFO] --- maven-javadoc-plugin:2.8.1:jar (module-javadocs) @ hadoop-dist ---
&gt; [INFO] Building jar: /hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-dist-2.7.1-javadoc.jar
&gt; [INFO] ------------------------------------------------------------------------
&gt; [INFO] Reactor Summary:
&gt; [INFO]
&gt; [INFO] Apache Hadoop Main ................................. SUCCESS [01:56 min]
&gt; [INFO] Apache Hadoop Project POM .......................... SUCCESS [ 42.134 s]
&gt; [INFO] Apache Hadoop Annotations .......................... SUCCESS [ 37.761 s]
&gt; [INFO] Apache Hadoop Assemblies ........................... SUCCESS [  0.125 s]
&gt; [INFO] Apache Hadoop Project Dist POM ..................... SUCCESS [ 23.183 s]
&gt; [INFO] Apache Hadoop Maven Plugins ........................ SUCCESS [ 25.962 s]
&gt; [INFO] Apache Hadoop MiniKDC .............................. SUCCESS [03:23 min]
&gt; [INFO] Apache Hadoop Auth ................................. SUCCESS [02:11 min]
&gt; [INFO] Apache Hadoop Auth Examples ........................ SUCCESS [ 10.145 s]
&gt; [INFO] Apache Hadoop Common ............................... SUCCESS [03:29 min]
&gt; [INFO] Apache Hadoop NFS .................................. SUCCESS [  4.724 s]
&gt; [INFO] Apache Hadoop KMS .................................. SUCCESS [02:35 min]
&gt; [INFO] Apache Hadoop Common Project ....................... SUCCESS [  0.024 s]
&gt; [INFO] Apache Hadoop HDFS ................................. SUCCESS [02:15 min]
&gt; [INFO] Apache Hadoop HttpFS ............................... SUCCESS [02:13 min]
&gt; [INFO] Apache Hadoop HDFS BookKeeper Journal .............. SUCCESS [ 38.598 s]
&gt; [INFO] Apache Hadoop HDFS-NFS ............................. SUCCESS [  3.213 s]
&gt; [INFO] Apache Hadoop HDFS Project ......................... SUCCESS [  0.032 s]
&gt; [INFO] hadoop-yarn ........................................ SUCCESS [  0.030 s]
&gt; [INFO] hadoop-yarn-api .................................... SUCCESS [ 29.193 s]
&gt; [INFO] hadoop-yarn-common ................................. SUCCESS [02:02 min]
&gt; [INFO] hadoop-yarn-server ................................. SUCCESS [  0.040 s]
&gt; [INFO] hadoop-yarn-server-common .......................... SUCCESS [  8.499 s]
&gt; [INFO] hadoop-yarn-server-nodemanager ..................... SUCCESS [ 12.283 s]
&gt; [INFO] hadoop-yarn-server-web-proxy ....................... SUCCESS [  2.359 s]
&gt; [INFO] hadoop-yarn-server-applicationhistoryservice ....... SUCCESS [  5.298 s]
&gt; [INFO] hadoop-yarn-server-resourcemanager ................. SUCCESS [ 15.095 s]
&gt; [INFO] hadoop-yarn-server-tests ........................... SUCCESS [  3.772 s]
&gt; [INFO] hadoop-yarn-client ................................. SUCCESS [  4.641 s]
&gt; [INFO] hadoop-yarn-server-sharedcachemanager .............. SUCCESS [  2.433 s]
&gt; [INFO] hadoop-yarn-applications ........................... SUCCESS [  0.019 s]
&gt; [INFO] hadoop-yarn-applications-distributedshell .......... SUCCESS [  1.884 s]
&gt; [INFO] hadoop-yarn-applications-unmanaged-am-launcher ..... SUCCESS [  1.263 s]
&gt; [INFO] hadoop-yarn-site ................................... SUCCESS [  0.020 s]
&gt; [INFO] hadoop-yarn-registry ............................... SUCCESS [  3.532 s]
&gt; [INFO] hadoop-yarn-project ................................ SUCCESS [  3.452 s]
&gt; [INFO] hadoop-mapreduce-client ............................ SUCCESS [  0.036 s]
&gt; [INFO] hadoop-mapreduce-client-core ....................... SUCCESS [ 15.195 s]
&gt; [INFO] hadoop-mapreduce-client-common ..................... SUCCESS [ 12.459 s]
&gt; [INFO] hadoop-mapreduce-client-shuffle .................... SUCCESS [  2.645 s]
&gt; [INFO] hadoop-mapreduce-client-app ........................ SUCCESS [  6.342 s]
&gt; [INFO] hadoop-mapreduce-client-hs ......................... SUCCESS [  3.845 s]
&gt; [INFO] hadoop-mapreduce-client-jobclient .................. SUCCESS [ 11.295 s]
&gt; [INFO] hadoop-mapreduce-client-hs-plugins ................. SUCCESS [  1.546 s]
&gt; [INFO] Apache Hadoop MapReduce Examples ................... SUCCESS [  4.573 s]
&gt; [INFO] hadoop-mapreduce ................................... SUCCESS [  2.164 s]
&gt; [INFO] Apache Hadoop MapReduce Streaming .................. SUCCESS [  7.874 s]
&gt; [INFO] Apache Hadoop Distributed Copy ..................... SUCCESS [ 19.660 s]
&gt; [INFO] Apache Hadoop Archives ............................. SUCCESS [  2.071 s]
&gt; [INFO] Apache Hadoop Rumen ................................ SUCCESS [  3.966 s]
&gt; [INFO] Apache Hadoop Gridmix .............................. SUCCESS [  3.215 s]
&gt; [INFO] Apache Hadoop Data Join ............................ SUCCESS [  1.818 s]
&gt; [INFO] Apache Hadoop Ant Tasks ............................ SUCCESS [  1.478 s]
&gt; [INFO] Apache Hadoop Extras ............................... SUCCESS [  2.037 s]
&gt; [INFO] Apache Hadoop Pipes ................................ SUCCESS [  5.880 s]
&gt; [INFO] Apache Hadoop OpenStack support .................... SUCCESS [  3.407 s]
&gt; [INFO] Apache Hadoop Amazon Web Services support .......... SUCCESS [ 40.013 s]
&gt; [INFO] Apache Hadoop Azure support ........................ SUCCESS [ 11.557 s]
&gt; [INFO] Apache Hadoop Client ............................... SUCCESS [  7.659 s]
&gt; [INFO] Apache Hadoop Mini-Cluster ......................... SUCCESS [  0.042 s]
&gt; [INFO] Apache Hadoop Scheduler Load Simulator ............. SUCCESS [  3.072 s]
&gt; [INFO] Apache Hadoop Tools Dist ........................... SUCCESS [  8.519 s]
&gt; [INFO] Apache Hadoop Tools ................................ SUCCESS [  0.014 s]
&gt; [INFO] Apache Hadoop Distribution ......................... SUCCESS [ 30.616 s]
&gt; [INFO] ------------------------------------------------------------------------
&gt; [INFO] BUILD SUCCESS
&gt; [INFO] ------------------------------------------------------------------------
&gt; [INFO] Total time: 29:26 min
&gt; [INFO] Finished at: 2015-09-01T00:47:31&#43;00:00
&gt; [INFO] Final Memory: 224M/785M
&gt; [INFO] ------------------------------------------------------------------------</code></pre>
</p>

<p>Para completar a compilação, executamos os testes, contudo, alguns deles podem apresentar falhas intermitentes (acontecem algumas vezes, outras não).</p>

<p>Os testes podem levar algumas horas para rodar por completo.</p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">mkdir hadoop-common-project/hadoop-common/target/test-classes/webapps/test

mvn test -Pnative -Drequire.snappy -Drequire.openssl -Dmaven.test.failure.ignore=true -Dsurefire.rerunFailingTestsCount=3

&gt; (...)</code></pre>
</p>

<p>(alguns testes com falha intermitente)</p>

<ul>
<li>org.apache.hadoop.ipc.TestDecayRpcScheduler#testAccumulate</li>
<li>org.apache.hadoop.ipc.TestDecayRpcScheduler#testPriority</li>
<li>org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetrics#testDataNodeTimeSpend</li>
<li>org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitCache#testDataXceiverHandlesRequestShortCircuitShmFailure</li>
</ul>

<p>&hellip;</p>

<p>No final desse procedimento, o pacote do Hadoop estará gerado em:</p>

<p><code>/hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz</code></p>

<h2 id="conclusão:ac8d87b01c866329a85ac2f7311bc677">Conclusão</h2>

<p>Esse procedimento mostra como o Hadoop pode ser customizado para necessidades específicas e que não requer um esforço muito grande.</p>

<p>Contudo, ter uma &ldquo;versão&rdquo; própria do Hadoop é uma decisão que deve ser tomada com cautela.</p>

<p>No momento, a gente considera que essa seja a melhor escolha para o nosso trabalho na Globo.com e estamos querendo formar um time para evoluir e dar suporte a essa plataforma. O maior benefício é a liberdade de escolher como configurar e melhorar nossa infraestrutura. O custo é não ter uma empresa especializada &ldquo;cuidando&rdquo; dessa responsabilidade.</p>

<p>No futuro, pode ser que mudemos esse modo de operação e busquemos uma distribuição &ldquo;profissional&rdquo; como Cloudera, Hortonworks ou outra.</p>

<p>Particularmente, eu prefiro manter uma plataforma própria.</p>

<p>&hellip;</p>

<p>Você trabalha com Hadoop ou tem experiência com as tecnologias envolvidas (Java)? Venha trabalhar conosco.</p>

<p><a href="http://talentos.globo.com/">http://talentos.globo.com/</a></p>

    </section>


  <footer class="post-footer">


    

    





<section class="author">
  <h4><a href="http://grandesdados.com/">Ciro Cavani</a></h4>
  
  <p>Sou formado em Engenharia de Computação pelo Instituto Tecnológico de Aeronáutica (ITA) e faço mestrado em Inteligência Artificial na Pontifícia Universidade Católica do Rio de Janeiro (PUC-Rio). Trabalho na Globo.com no time de Personalização que é responsável pelo desenvolvimento da Plataforma de BigData usada em Produtos de Dados, como o Sistema de Recomendação. Tenho experiência no desenvolvimento de plataformas para coleta, armazenamento e análise de grande volume de dados com objetivo de agregar valor ao negócio da empresa.</p>
  
  <div class="author-meta">
    <span class="author-location icon-location">Rio de Janeiro, RJ</span>
    <span class="author-link icon-link"><a href="https://www.linkedin.com/in/cirocavani">https://www.linkedin.com/in/cirocavani</a></span>
  </div>
</section>



    
    <section class="share">
      <h4>Share this post</h4>
      <a class="icon-twitter" style="font-size: 1.4em" href="https://twitter.com/share?text=Compila%c3%a7%c3%a3o%20do%20Hadoop%20para%20CentOS6%20%2f%20RHEL6%20usando%20Docker&amp;url=http%3a%2f%2fgrandesdados.com%2fpost%2fcompilacao-do-hadoop-para-centos6-rhel6-usando-docker%2f"
          onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
          <span class="hidden">Twitter</span>
      </a>
      <a class="icon-facebook" style="font-size: 1.4em" href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2fgrandesdados.com%2fpost%2fcompilacao-do-hadoop-para-centos6-rhel6-usando-docker%2f"
          onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
          <span class="hidden">Facebook</span>
      </a>
      <a class="icon-google-plus" style="font-size: 1.4em" href="https://plus.google.com/share?url=http%3a%2f%2fgrandesdados.com%2fpost%2fcompilacao-do-hadoop-para-centos6-rhel6-usando-docker%2f"
         onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
          <span class="hidden">Google+</span>
      </a>
    </section>
    

    
    
    <div id="disqus_thread"></div>
    <script type="text/javascript">
      var disqus_shortname = 'grandesdados';
      (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    
    

  </footer>
</article>

</main>
    <footer class="site-footer clearfix">
        <section class="copyright"><a href="">Grandes Dados</a> Todos os direitos reservados - 2015</section>
        
        <section class="poweredby">Proudly generated by <a class="icon-hugo" href="http://gohugo.io">HUGO</a>, with <a class="icon-theme" href="https://github.com/vjeantet/hugo-theme-casper">Casper</a> theme</section>
        
    </footer>
    </div>
    <script type="text/javascript" src="http://grandesdados.com/js/jquery.js"></script>
    <script type="text/javascript" src="http://grandesdados.com/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="http://grandesdados.com/js/index.js"></script>

</body>
</html>

