<!DOCTYPE html>
<html lang="pt-br">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

  	<meta property="og:title" content=" Otimização dos parâmetros do Spark ALS (Collaborative Filtering) usando MOE &middot;  Grandes Dados" />
  	<meta property="og:site_name" content="Grandes Dados" />
  	<meta property="og:url" content="http://grandesdados.com/post/otimizacao-dos-parametros-do-spark-als-collaborative-filtering-usando-moe/" />

    
        <meta property="og:image" content="http://grandesdados.com/images/placeholder-share.jpg" />
    


    
  	<meta property="og:type" content="article" />

    <meta property="og:article:published_time" content="2015-09-24T19:44:08-03:00" />

    
    <meta property="og:article:tag" content="Tutorial" />
    
    <meta property="og:article:tag" content="Otimização" />
    
    <meta property="og:article:tag" content="Sistema de Recomendação" />
    
    <meta property="og:article:tag" content="Algoritmos" />
    
    <meta property="og:article:tag" content="Spark" />
    
    

    <title>
         Otimização dos parâmetros do Spark ALS (Collaborative Filtering) usando MOE &middot;  Grandes Dados
    </title>

    
        <meta name="description" content="Blog de BigData" />
    

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="http://grandesdados.com/images/favicon.ico">
	  <link rel="apple-touch-icon" href="http://grandesdados.com/images/apple-touch-icon.png" />

    <link rel="stylesheet" type="text/css" href="http://grandesdados.com/css/screen.css" />
    <link rel="stylesheet" type="text/css" href="http://grandesdados.com/css/nav.css" />
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400|Inconsolata" />


    
      
          <link href="http://grandesdados.com/index.xml" rel="alternate" type="application/rss+xml" title="Grandes Dados" />
      
      
    
    <meta name="generator" content="Hugo 0.15" />

    <link rel="canonical" href="http://grandesdados.com/post/otimizacao-dos-parametros-do-spark-als-collaborative-filtering-usando-moe/" />

    
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-38960920-6', 'auto');
      ga('send', 'pageview');

    </script>
    

    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/styles/solarized_dark.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

</head>
<body class="nav-closed">

  <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
        
        
        
            
            <li class="nav-opened" role="presentation">
            	<a href="http://grandesdados.com/">Blog</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="https://github.com/GrandesDados">GitHub</a>
            </li>
        
    </ul>
    
    
    <a class="subscribe-button icon-feed" href="http://grandesdados.com/index.xml">Subscribe</a>
    
</div>
<span class="nav-cover"></span>


 <div class="site-wrapper">




<header class="main-header post-head no-cover">
  <nav class="main-nav clearfix">


  
  
      <a class="menu-button" href="#"><span class="burger">&#9776;</span><span class="word">Menu</span></a>
  
  </nav>
</header>



<main class="content" role="main">




  <article class="post post">

    <header class="post-header">
        <h1 class="post-title">Otimização dos parâmetros do Spark ALS (Collaborative Filtering) usando MOE</h1>
        <small></small>

        <section class="post-meta">
        
          <time class="post-date" datetime="2015-09-24T19:44:08-03:00">
            Sep 24, 2015
          </time>
        
         
          <span class="post-tag small"><a href="http://grandesdados.com/tags/tutorial/">#Tutorial</a></span>
         
          <span class="post-tag small"><a href="http://grandesdados.com/tags/otimiza%C3%A7%C3%A3o/">#Otimização</a></span>
         
          <span class="post-tag small"><a href="http://grandesdados.com/tags/sistema-de-recomenda%C3%A7%C3%A3o/">#Sistema de Recomendação</a></span>
         
          <span class="post-tag small"><a href="http://grandesdados.com/tags/algoritmos/">#Algoritmos</a></span>
         
          <span class="post-tag small"><a href="http://grandesdados.com/tags/spark/">#Spark</a></span>
         
        </section>
    </header>
  
    <section class="post-content">
      <p>Esse tutorial é sobre otimização de parâmetros em modelos de machine learning. Para esse tutorial, a ferramenta utilizada é o MOE, Metric Optimization Engine, desenvolvido pelo Yelp que implementa o algoritmo de busca usando Gaussian Process. O algoritmo escolhido para ter os parâmetros otimizados é o Collaborative Filtering baseado na fatoração da matriz de preferências. De forma genérica, esse é um processo que pode ser facilmente adaptado para outros algoritmos e permite sistematizar a árdua tarefa de escolher os melhores parâmetros para um modelo.</p>

<p><a href="http://yelp.github.io/MOE/">http://yelp.github.io/MOE/</a></p>

<blockquote>
<p>MOE (Metric Optimization Engine) is an efficient way to optimize a system’s parameters, when evaluating parameters is time-consuming or expensive.</p>

<p>How does MOE work?</p>

<ol>
<li>Build a Gaussian Process (GP) with the historical data</li>
<li>Optimize the hyperparameters of the Gaussian Process</li>
<li>Find the point(s) of highest Expected Improvement (EI)</li>
<li>Return the point(s) to sample, then repeat</li>
</ol>
</blockquote>

<p>Primeiramente, é feita a instalação do MOE. Nesse processo, é necessário configurar o ambiente para compilar as dependências do projeto e o código que é composto por Python e C++. No final desse procedimento, o serviço do MOE estará disponível como um servidor REST e a API Python que pode ser usada para definir o procedimento de otimização.</p>

<p>O procedimento de instalação em detalhes é descrito aqui:</p>

<p><a href="http://yelp.github.io/MOE/install.html#install-from-source">http://yelp.github.io/MOE/install.html#install-from-source</a></p>


<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">mkdir grandesdados-opt
cd grandesdados-opt

virtualenv --no-site-packages --python=python2.7 moe-env

&gt; Running virtualenv with interpreter /usr/bin/python2.7
&gt; New python executable in moe-env/bin/python2.7
&gt; Also creating executable in moe-env/bin/python
&gt; Installing setuptools, pip, wheel...done.

source moe-env/bin/activate

git clone https://github.com/Yelp/MOE.git
cd MOE

pip install -r requirements.txt

&gt; (...)
&gt; Successfully installed (...)

python setup.py install

&gt; (...)

pserve --reload development.ini

&gt; (...)
&gt; Starting server in PID 23232.
&gt; serving on 0.0.0.0:6543 view at http://127.0.0.1:6543

# (nesse momento, esse terminal fica &#39;preso&#39; mostrando o log do servidor do MOE)</code></pre>


<p>O próximo passo é instalar o algoritmo que tem parâmetros que precisam ser otimizados.</p>

<p>Nesse tutorial, será usado o algoritmo de Collaborative Filtering baseado na fatoração da matriz de preferências que gera um vetor para cada usuário e item da matriz original. Nesse algoritmo, os parâmetros são a dimensão do vetor a ser gerado (fatores latentes), o número de iterações para fatoração da matriz e o parâmetro de regularização usado na fatoração.</p>

<p>O DataSet usado é um sample MovieLens que já vem na distribuição do Spark. São 1501 ratings, 30 usuários e 100 filmes.</p>

<p>O código pode ser análisado aqui:</p>

<p><a href="https://github.com/apache/spark/blob/v1.5.0/examples/src/main/scala/org/apache/spark/examples/ml/MovieLensALS.scala">https://github.com/apache/spark/blob/v1.5.0/examples/src/main/scala/org/apache/spark/examples/ml/MovieLensALS.scala</a></p>

<p>(procedimento na mesma pasta anterior <code>grandesdados-opt</code>)</p>


<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">curl -L -O http://ftp.unicamp.br/pub/apache/spark/spark-1.5.0/spark-1.5.0-bin-hadoop2.6.tgz
tar zxf spark-1.5.0-bin-hadoop2.6.tgz
cd spark-1.5.0-bin-hadoop2.6/

cp conf/log4j.properties{.template,}
sed -i s/log4j\.rootCategory\=INFO/log4j\.rootCategory\=ERROR/1 conf/log4j.properties

echo &#34;spark.ui.showConsoleProgress=false&#34; &gt; conf/spark-defaults.conf</code></pre>


<p>Executando o exemplo do MovieLens (a saída são os parâmetros):</p>


<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">./bin/run-example ml.MovieLensALS

&gt; Error: Missing option --ratings
&gt; Error: Missing option --movies
&gt; MovieLensALS: an example app for ALS on MovieLens data.
&gt; Usage: MovieLensALS [options]
&gt; 
&gt;   --ratings &lt;value&gt;
&gt;         path to a MovieLens dataset of ratings
&gt;   --movies &lt;value&gt;
&gt;         path to a MovieLens dataset of movies
&gt;   --rank &lt;value&gt;
&gt;         rank, default: 10
&gt;   --maxIter &lt;value&gt;
&gt;         max number of iterations, default: 10
&gt;   --regParam &lt;value&gt;
&gt;         regularization parameter, default: 0.1
&gt;   --numBlocks &lt;value&gt;
&gt;         number of blocks, default: 10
&gt; 
&gt; Example command line to run this app:
&gt; 
&gt;  bin/spark-submit --class org.apache.spark.examples.ml.MovieLensALS \
&gt;   examples/target/scala-*/spark-examples-*.jar \
&gt;   --rank 10 --maxIter 15 --regParam 0.1 \
&gt;   --movies data/mllib/als/sample_movielens_movies.txt \
&gt;   --ratings data/mllib/als/sample_movielens_ratings.txt</code></pre>


<p>Fazendo uma execução:</p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">time ./bin/run-example ml.MovieLensALS \
--rank 10 --maxIter 15 --regParam 0.1 \
--movies data/mllib/als/sample_movielens_movies.txt \
--ratings data/mllib/als/sample_movielens_ratings.txt

&gt; Got 1501 ratings from 30 users on 100 movies.                                   
&gt; Training: 1169, test: 332.
&gt; Test RMSE = 0.9815785141168548.                                                 
&gt; Found 0 false positives                                                         
&gt; 
&gt; real	0m22.441s
&gt; user	0m56.320s
&gt; sys	0m1.847s</code></pre>
</p>

<p>Para fazer a otimização, o MOE requer que o problema seja modelado como uma função do vetor de parâmetros para um valor escalar. O objetivo da ferramenta é minimizar essa função.</p>

<p>Para o problema do ALS, por simplicidade, vamos aproveitar que o exemplo já calcula o RMSE e usar a função que mapeia o vetor do Número de Fatores Latentes, Número de Iterações e Regularização para o RMSE. Faz sentido o objetivo ser minimizar o RMSE.</p>

<p>Na pasta <code>grandesdados-opt</code>, crie o arquivo <code>func.sh</code> que mapeia a função desejada:</p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">#!/bin/bash

cd spark-1.5.0-bin-hadoop2.6/

./bin/run-example ml.MovieLensALS \
--rank $1 --maxIter $2 --regParam $3 \
--movies data/mllib/als/sample_movielens_movies.txt \
--ratings data/mllib/als/sample_movielens_ratings.txt 2&gt;&amp;1 \
| sed -n &#39;s/\(Test RMSE =\) \([0-9]*\.[0-9]*\)\./\2/p&#39;</code></pre>
</p>

<p>Dessa forma, teremos:</p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">chmod &#43;x func.sh

./func.sh 10 15 0.1

&gt; 0.9815785141168546</code></pre>
</p>

<p>Agora podemos definir o procedimento de otimização como um experimento do MOE.</p>

<p>O experimento é criado com o domínio dos parâmetros que estamos querendo otimizar. Dado que estamos trabalhando com um DataSet limitado, podemos restringir os valores.</p>

<p>Nesse exemplo, estamos usando:</p>

<ul>
<li>Número de Fatores Latentes: entre 5 e 50</li>
<li>Número de Iterações da Fatoração: entre 5 e 20</li>
<li>Regularização da Fatoração: entre 0.001 e 1</li>
</ul>

<p>Vamos assumir como primeiro ponto &lsquo;ótimo&rsquo; o que vem documentado no exemplo, ou seja, 10, 15 e 0,1.</p>

<p>A busca por uma solução muito boa pode envolver muitas iterações do processo de otimização, nesse exemplo vamos usar 20, mas poderia ser 100 ou 400 para uma busca mais completa.</p>

<p>Na pasta <code>grandesdados-opt</code>, crie o arquivo <code>opt.py</code> que define o procedimento de otimização:</p>

<p>
<pre><code class="language-python" style="font-size: medium; line-height: 1.2;">import subprocess

from moe.easy_interface.experiment import Experiment
from moe.easy_interface.simple_endpoint import gp_next_points
from moe.optimal_learning.python.data_containers import SamplePoint

def function_to_minimize(x):
    f = &#34;./func.sh {0:} {1:} {2:}&#34;.format(int(x[0]), int(x[1]), x[2])
    print f
    y = subprocess.Popen(f, shell=True, stdout=subprocess.PIPE).stdout.read().strip()
    if y: print y
    return float(y)

if __name__ == &#39;__main__&#39;:
    exp = Experiment([[5, 50], [5, 20], [0.001, 1]])

    xmin = []
    ymin = 0.0

    for i in range(20):
        print &#34;Sample {0:}&#34;.format(i)
        try:
            x = [10.0, 15.0, 0.1] if i == 0 else gp_next_points(exp)[0]
            y = function_to_minimize(x)
            exp.historical_data.append_sample_points([
                SamplePoint(x, y, 0.05),
            ])
            if not xmin or y &lt; ymin:
                xmin, ymin = x, y
        except ValueError:
            print &#34;error&#34;
        print

    print str(xmin)
    print str(ymin)</code></pre>
</p>

<p>Por fim, o resultado:
<br/>(necessário estar dentro do virtualenv onde o MOE foi instalado)</p>

<p>
<pre><code class="language-sh" style="font-size: medium; line-height: 1.2;">python2 opt.py

&gt; Sample 0
&gt; ./func.sh 10 15 0.1
&gt; 0.9815785141168545
&gt; (...)
&gt; Sample 19
&gt; ./func.sh 16 19 0.41989952735
&gt; error
&gt; 
&gt; [46.6604641336, 19.9410400182, 0.0409527639665]
&gt; 0.977384860516</code></pre>
</p>

<p>Como podemos ver, os parâmetros 46 para Número de Fatores Latentes, 19 para Iterações da Fatoração e 0,041 para Regularização resultaram em um erro menor nesse dataset de exemplo.</p>

<p>Para mais informações sobre otimização usando o MOE, consulte a documentação.</p>

    </section>


  <footer class="post-footer">


    

    





<section class="author">
  <h4><a href="http://grandesdados.com/">Ciro Cavani</a></h4>
  
  <p>Sou formado em Engenharia de Computação pelo Instituto Tecnológico de Aeronáutica (ITA) e faço mestrado em Inteligência Artificial na Pontifícia Universidade Católica do Rio de Janeiro (PUC-Rio). Trabalho na Globo.com no time de Personalização que é responsável pelo desenvolvimento da Plataforma de BigData usada em Produtos de Dados, como o Sistema de Recomendação. Tenho experiência no desenvolvimento de plataformas para coleta, armazenamento e análise de grande volume de dados com objetivo de agregar valor ao negócio da empresa.</p>
  
  <div class="author-meta">
    <span class="author-location icon-location">Rio de Janeiro, RJ</span>
    <span class="author-link icon-link"><a href="https://www.linkedin.com/in/cirocavani">https://www.linkedin.com/in/cirocavani</a></span>
  </div>
</section>



    
    <section class="share">
      <h4>Share this post</h4>
      <a class="icon-twitter" style="font-size: 1.4em" href="https://twitter.com/share?text=Otimiza%c3%a7%c3%a3o%20dos%20par%c3%a2metros%20do%20Spark%20ALS%20%28Collaborative%20Filtering%29%20usando%20MOE&amp;url=http%3a%2f%2fgrandesdados.com%2fpost%2fotimizacao-dos-parametros-do-spark-als-collaborative-filtering-usando-moe%2f"
          onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
          <span class="hidden">Twitter</span>
      </a>
      <a class="icon-facebook" style="font-size: 1.4em" href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2fgrandesdados.com%2fpost%2fotimizacao-dos-parametros-do-spark-als-collaborative-filtering-usando-moe%2f"
          onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
          <span class="hidden">Facebook</span>
      </a>
      <a class="icon-google-plus" style="font-size: 1.4em" href="https://plus.google.com/share?url=http%3a%2f%2fgrandesdados.com%2fpost%2fotimizacao-dos-parametros-do-spark-als-collaborative-filtering-usando-moe%2f"
         onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
          <span class="hidden">Google+</span>
      </a>
    </section>
    

    
    
    <div id="disqus_thread"></div>
    <script type="text/javascript">
      var disqus_shortname = 'grandesdados';
      (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    
    

  </footer>
</article>

</main>
    <footer class="site-footer clearfix">
        <section class="copyright"><a href="">Grandes Dados</a> Todos os direitos reservados - 2015</section>
        
        <section class="poweredby">Proudly generated by <a class="icon-hugo" href="http://gohugo.io">HUGO</a>, with <a class="icon-theme" href="https://github.com/vjeantet/hugo-theme-casper">Casper</a> theme</section>
        
    </footer>
    </div>
    <script type="text/javascript" src="http://grandesdados.com/js/jquery.js"></script>
    <script type="text/javascript" src="http://grandesdados.com/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="http://grandesdados.com/js/index.js"></script>

</body>
</html>

