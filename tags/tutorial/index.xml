<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial on Grandes Dados</title>
    <link>http://grandesdados.com/tags/tutorial/</link>
    <description>Recent content in Tutorial on Grandes Dados</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <copyright>Todos os direitos reservados - 2015</copyright>
    <lastBuildDate>Fri, 11 Sep 2015 08:10:00 -0300</lastBuildDate>
    <atom:link href="http://grandesdados.com/tags/tutorial/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Compilação do Spark 1.5 (com bugfix)</title>
      <link>http://grandesdados.com/post/compilacao-do-spark-15-com-bugfix/</link>
      <pubDate>Fri, 11 Sep 2015 08:10:00 -0300</pubDate>
      
      <guid>http://grandesdados.com/post/compilacao-do-spark-15-com-bugfix/</guid>
      <description>

&lt;p&gt;Aproveitando que foi feito o lançamento da versão 1.5.0 do Spark, esse tutorial é sobre a construção do pacote do Spark usando o branch atualizado. O branch foi criado para fazer a estabilização do código que deu origem ao primeiro release. Esse branch continua recebendo atualizações importantes que farão parte de releases bugfix no futuro. Com esse procedimento, é possível gerar o pacote com essas últimas atualizações (e até customizar com alterações próprias) antecipando correções que podem ajudar em produção. Importante entender que ao usar uma versão que não passou pelo release implica em riscos que devem ser mitigados com muitos testes.&lt;/p&gt;

&lt;p&gt;Mais informações sobre a construção do Spark podem ser obtidas na documentação &lt;a href=&#34;http://spark.apache.org/docs/latest/building-spark.html&#34;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Mais informações sobre a última versão Spark 1.5.0 no &lt;a href=&#34;http://spark.apache.org/releases/spark-release-1-5-0.html&#34;&gt;Release Notes&lt;/a&gt; e no blog da Databricks &lt;a href=&#34;https://databricks.com/blog/2015/09/09/announcing-spark-1-5.html&#34;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;pré-requisito:a471447a7b0c139f517b6888cdad9c6e&#34;&gt;Pré-requisito&lt;/h2&gt;

&lt;p&gt;O procedimento consiste em: provisionar o ambiente; fazer uma cópia do branch estável da última versão, e; gerar o pacote binário e os artefatos do Maven.&lt;/p&gt;

&lt;p&gt;As ferramentas necessárias para construção são git, Java 7 e Maven 3.3.&lt;/p&gt;

&lt;p&gt;Todo o procedimento é executado na linha de comando do terminal.&lt;/p&gt;

&lt;p&gt;(é assumido que o git já está instalado)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Java&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A versão usada nesse procedimento é o Java 7 para o qual a Oracle já terminou o ciclo de desenvolvimento das releases públicas (gratuitas). Contudo, essa é a versão que tem melhor suporte nas ferramentas que estaremos usando com Spark.&lt;/p&gt;

&lt;p&gt;(também tem suporte para o Java 8, mas o interesse é usar esse pacote no Hadoop 2.7 que ainda não suporta oficialmente essa versão)&lt;/p&gt;

&lt;p&gt;Segue o procedimento para Linux e MacOSX.&lt;/p&gt;

&lt;p&gt;(Linux)&lt;/p&gt;

&lt;p&gt;No Linux, para o Java, é usado o JDK da Oracle.&lt;/p&gt;

&lt;p&gt;(nesse procedimento, foi usado o ArchLinux atualizado até essa primeira semana de Setembro)&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;wget --no-check-certificate --no-cookies --header &amp;#34;Cookie: oraclelicense=accept-securebackup-cookie&amp;#34; http://download.oracle.com/otn-pub/java/jdk/7u80-b15/jdk-7u80-linux-x64.tar.gz

tar zxf jdk-7u80-linux-x64.tar.gz

export JAVA_HOME=`pwd`/jdk1.7.0_80
export PATH=$JAVA_HOME/bin:$PATH

java -version

&amp;gt; java version &amp;#34;1.7.0_80&amp;#34;
&amp;gt; Java(TM) SE Runtime Environment (build 1.7.0_80-b15)
&amp;gt; Java HotSpot(TM) 64-Bit Server VM (build 24.80-b11, mixed mode)&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;(OSX)&lt;/p&gt;

&lt;p&gt;No MacOSX, é necessário baixar o pacote no site da Oracle e fazer a instalação.&lt;/p&gt;

&lt;p&gt;Download do Java 7 &lt;a href=&#34;http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html#jdk-7u80-oth-JPR&#34;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;No terminal, a versão específica do Java pode ser configurada ajustando a variável de ambiente:&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;export JAVA_HOME=&amp;#34;$(/usr/libexec/java_home -v 1.7)&amp;#34;

java -version

&amp;gt; java version &amp;#34;1.7.0_80&amp;#34;
&amp;gt; Java(TM) SE Runtime Environment (build 1.7.0_80-b15)
&amp;gt; Java HotSpot(TM) 64-Bit Server VM (build 24.80-b11, mixed mode)&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Maven&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A construção do Spark depende da versão 3.3 do Maven.&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;wget http://archive.apache.org/dist/maven/maven-3/3.3.3/binaries/apache-maven-3.3.3-bin.tar.gz

tar zxf apache-maven-3.3.3-bin.tar.gz

export PATH=`pwd`/apache-maven-3.3.3/bin

mvn -version

&amp;gt; Apache Maven 3.3.3 (7994120775791599e205a5524ec3e0dfe41d4a06; 2015-04-22T08:57:37-03:00)
&amp;gt; Maven home: /home/cavani/Software/apache-maven-3.3.3
&amp;gt; Java version: 1.7.0_80, vendor: Oracle Corporation
&amp;gt; Java home: /home/cavani/Software/jdk1.7.0_80/jre
&amp;gt; Default locale: en_US, platform encoding: UTF-8
&amp;gt; OS name: &amp;#34;linux&amp;#34;, version: &amp;#34;4.0.4-2-arch&amp;#34;, arch: &amp;#34;amd64&amp;#34;, family: &amp;#34;unix&amp;#34;&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;h2 id=&#34;compilação:a471447a7b0c139f517b6888cdad9c6e&#34;&gt;Compilação&lt;/h2&gt;

&lt;p&gt;Primeiramente é criado um clone local do repositório do Spark no qual é desenvolvido a versão 1.5 (estável).&lt;/p&gt;

&lt;p&gt;(use &lt;code&gt;--depth 1&lt;/code&gt; para baixar apenas os arquivos finais, sem o histórico de mudanças, diminui o download)&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;git clone https://github.com/apache/spark.git --branch branch-1.5 spark-1.5

&amp;gt; Cloning into &amp;#39;spark-1.5&amp;#39;...
&amp;gt; remote: Counting objects: 256928, done.
&amp;gt; remote: Total 256928 (delta 0), reused 0 (delta 0), pack-reused 256928
&amp;gt; Receiving objects: 100% (256928/256928), 121.38 MiB | 1.23 MiB/s, done.
&amp;gt; Resolving deltas: 100% (108225/108225), done.
&amp;gt; Checking connectivity... done.

cd spark-1.5&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;A partir desse branch serão criados todos os releases 1.5.x.&lt;/p&gt;

&lt;p&gt;Já foi feito o release da tag v1.5.0 e está aberto o desenvolvimento da versão 1.5.1 (ou seja, a versão corrente no branch é a 1.5.1-SNAPSHOT).&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;git log --oneline -30

&amp;gt; 89d351b Revert &amp;#34;[SPARK-6350] [MESOS] Fine-grained mode scheduler respects mesosExecutor.cores&amp;#34;
&amp;gt; (...)
&amp;gt; 2b270a1 Preparing development version 1.5.1-SNAPSHOT
&amp;gt; 908e37b Preparing Spark release v1.5.0-rc3
&amp;gt; 1c752b8 [SPARK-10341] [SQL] fix memory starving in unsafe SMJ&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;O versionamento será com base na versão do último release e a identificação dos bugfix será feita no nome do pacote, preservado a substituição transparente da versão oficial pela atualizada.&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;mvn help:evaluate -Dexpression=project.version | grep -v INFO | grep -v WARNING | grep -v Download

&amp;gt; 1.5.1-SNAPSHOT

mvn versions:set -DnewVersion=1.5.0 -DgenerateBackupPoms=false

&amp;gt; (...)
&amp;gt; [INFO] Reactor Summary:
&amp;gt; [INFO] 
&amp;gt; [INFO] Spark Project Parent POM ........................... SUCCESS [  4.559 s]
&amp;gt; (...)
&amp;gt; [INFO] BUILD SUCCESS
&amp;gt; (...)&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;Por fim, a construção do pacote.&lt;/p&gt;

&lt;p&gt;Nesse caso estaremos construindo um pacote com suporte ao YARN no Hadoop 2.7.1, suporte Hive com JDBC.&lt;/p&gt;

&lt;p&gt;Estamos colocando no nome do pacote o número do último commit.&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;export MAVEN_OPTS=&amp;#34;-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m&amp;#34;

./make-distribution.sh --name 89d351b --tgz --skip-java-test -Phadoop-2.6 -Pyarn -Phive -Phive-thriftserver -Dhadoop.version=2.7.1

&amp;gt; (...)
&amp;gt; [INFO] Reactor Summary:
&amp;gt; [INFO] 
&amp;gt; [INFO] Spark Project Parent POM ........................... SUCCESS [  3.841 s]
&amp;gt; [INFO] Spark Project Launcher ............................. SUCCESS [ 12.819 s]
&amp;gt; [INFO] Spark Project Networking ........................... SUCCESS [ 10.980 s]
&amp;gt; [INFO] Spark Project Shuffle Streaming Service ............ SUCCESS [  6.876 s]
&amp;gt; [INFO] Spark Project Unsafe ............................... SUCCESS [ 15.828 s]
&amp;gt; [INFO] Spark Project Core ................................. SUCCESS [03:19 min]
&amp;gt; [INFO] Spark Project Bagel ................................ SUCCESS [  7.048 s]
&amp;gt; [INFO] Spark Project GraphX ............................... SUCCESS [ 18.493 s]
&amp;gt; [INFO] Spark Project Streaming ............................ SUCCESS [ 41.120 s]
&amp;gt; [INFO] Spark Project Catalyst ............................. SUCCESS [01:01 min]
&amp;gt; [INFO] Spark Project SQL .................................. SUCCESS [01:22 min]
&amp;gt; [INFO] Spark Project ML Library ........................... SUCCESS [01:13 min]
&amp;gt; [INFO] Spark Project Tools ................................ SUCCESS [  2.460 s]
&amp;gt; [INFO] Spark Project Hive ................................. SUCCESS [ 58.477 s]
&amp;gt; [INFO] Spark Project REPL ................................. SUCCESS [ 11.646 s]
&amp;gt; [INFO] Spark Project YARN ................................. SUCCESS [ 14.443 s]
&amp;gt; [INFO] Spark Project Hive Thrift Server ................... SUCCESS [ 11.609 s]
&amp;gt; [INFO] Spark Project Assembly ............................. SUCCESS [02:02 min]
&amp;gt; [INFO] Spark Project External Twitter ..................... SUCCESS [  8.653 s]
&amp;gt; [INFO] Spark Project External Flume Sink .................. SUCCESS [  5.997 s]
&amp;gt; [INFO] Spark Project External Flume ....................... SUCCESS [ 12.408 s]
&amp;gt; [INFO] Spark Project External Flume Assembly .............. SUCCESS [  3.959 s]
&amp;gt; [INFO] Spark Project External MQTT ........................ SUCCESS [ 22.884 s]
&amp;gt; [INFO] Spark Project External MQTT Assembly ............... SUCCESS [  8.830 s]
&amp;gt; [INFO] Spark Project External ZeroMQ ...................... SUCCESS [  8.407 s]
&amp;gt; [INFO] Spark Project External Kafka ....................... SUCCESS [ 14.933 s]
&amp;gt; [INFO] Spark Project Examples ............................. SUCCESS [01:52 min]
&amp;gt; [INFO] Spark Project External Kafka Assembly .............. SUCCESS [  7.171 s]
&amp;gt; [INFO] Spark Project YARN Shuffle Service ................. SUCCESS [  7.010 s]
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] BUILD SUCCESS
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] Total time: 16:08 min
&amp;gt; [INFO] Finished at: 2015-09-11T06:44:55-03:00
&amp;gt; [INFO] Final Memory: 417M/1553M
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; (...)&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;Resultado:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;spark-1.5.0-bin-89d351b.tgz&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;(Artefatos do Maven)&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;rm -rf ~/.m2/repository/org/apache/spark

mvn install -Phadoop-2.6 -Pyarn -Phive -Phive-thriftserver -Dhadoop.version=2.7.1 -DskipTests

&amp;gt; (...)
&amp;gt; [INFO] Reactor Summary:
&amp;gt; [INFO] 
&amp;gt; [INFO] Spark Project Parent POM ........................... SUCCESS [  4.339 s]
&amp;gt; [INFO] Spark Project Launcher ............................. SUCCESS [ 14.078 s]
&amp;gt; [INFO] Spark Project Networking ........................... SUCCESS [  8.555 s]
&amp;gt; [INFO] Spark Project Shuffle Streaming Service ............ SUCCESS [  3.540 s]
&amp;gt; [INFO] Spark Project Unsafe ............................... SUCCESS [  3.395 s]
&amp;gt; [INFO] Spark Project Core ................................. SUCCESS [01:22 min]
&amp;gt; [INFO] Spark Project Bagel ................................ SUCCESS [  7.293 s]
&amp;gt; [INFO] Spark Project GraphX ............................... SUCCESS [ 15.367 s]
&amp;gt; [INFO] Spark Project Streaming ............................ SUCCESS [ 26.005 s]
&amp;gt; [INFO] Spark Project Catalyst ............................. SUCCESS [ 49.232 s]
&amp;gt; [INFO] Spark Project SQL .................................. SUCCESS [ 48.866 s]
&amp;gt; [INFO] Spark Project ML Library ........................... SUCCESS [01:01 min]
&amp;gt; [INFO] Spark Project Tools ................................ SUCCESS [  8.979 s]
&amp;gt; [INFO] Spark Project Hive ................................. SUCCESS [ 29.601 s]
&amp;gt; [INFO] Spark Project REPL ................................. SUCCESS [ 19.661 s]
&amp;gt; [INFO] Spark Project YARN ................................. SUCCESS [ 16.976 s]
&amp;gt; [INFO] Spark Project Hive Thrift Server ................... SUCCESS [ 13.583 s]
&amp;gt; [INFO] Spark Project Assembly ............................. SUCCESS [02:01 min]
&amp;gt; [INFO] Spark Project External Twitter ..................... SUCCESS [  9.734 s]
&amp;gt; [INFO] Spark Project External Flume Sink .................. SUCCESS [ 10.291 s]
&amp;gt; [INFO] Spark Project External Flume ....................... SUCCESS [ 12.282 s]
&amp;gt; [INFO] Spark Project External Flume Assembly .............. SUCCESS [  4.252 s]
&amp;gt; [INFO] Spark Project External MQTT ........................ SUCCESS [ 21.910 s]
&amp;gt; [INFO] Spark Project External MQTT Assembly ............... SUCCESS [  8.383 s]
&amp;gt; [INFO] Spark Project External ZeroMQ ...................... SUCCESS [  7.677 s]
&amp;gt; [INFO] Spark Project External Kafka ....................... SUCCESS [ 13.317 s]
&amp;gt; [INFO] Spark Project Examples ............................. SUCCESS [01:45 min]
&amp;gt; [INFO] Spark Project External Kafka Assembly .............. SUCCESS [  6.813 s]
&amp;gt; [INFO] Spark Project YARN Shuffle Service ................. SUCCESS [  7.544 s]
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] BUILD SUCCESS
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] Total time: 12:24 min
&amp;gt; [INFO] Finished at: 2015-09-11T07:52:35-03:00
&amp;gt; [INFO] Final Memory: 102M/1349M
&amp;gt; [INFO] ------------------------------------------------------------------------

cd ~/.m2/repository
tar cf spark-1.5.0-m2-89d351b.tar org/apache/spark

cd -
mv ~/.m2/repository/spark-1.5.0-m2-89d351b.tar .&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;Resultado:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;spark-1.5.0-m2-89d351b.tar&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusão:a471447a7b0c139f517b6888cdad9c6e&#34;&gt;Conclusão&lt;/h2&gt;

&lt;p&gt;O Spark é um framework que vem evoluindo rapidamente, com contribuições das mais diversas origem. Praticamente todos os grandes de BigData estão contribuindo com o Spark. Muitas vezes, surgem novas funcionalidades que podem agregar muito valor nas suas aplicações. Outras vezes, são bugs corrigidos que contribuem para a estabilidade de uma aplicação que já existe. Também tem o &amp;lsquo;prazer&amp;rsquo; de ser um &amp;lsquo;early adopter&amp;rsquo;. Seja qual for o motivo, esse procedimento mostra que o trabalho para ter um pacote do Spark é bem fácil e, por experiência, esse é um fator bastante relevante para ganhar tempo e gerar máximo valor.&lt;/p&gt;

&lt;p&gt;Nos próximos artigos, vou falar mais de como usar o Spark para desenvolver um aplicação que roda no Hadoop.&lt;/p&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;Você trabalha com Spark ou tem experiência com as tecnologias envolvidas? Venha trabalhar conosco.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://talentos.globo.com/&#34;&gt;http://talentos.globo.com/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Compilação do Hadoop para CentOS6 / RHEL6 usando Docker</title>
      <link>http://grandesdados.com/post/compilacao-do-hadoop-para-centos6-rhel6-usando-docker/</link>
      <pubDate>Mon, 31 Aug 2015 22:45:23 -0300</pubDate>
      
      <guid>http://grandesdados.com/post/compilacao-do-hadoop-para-centos6-rhel6-usando-docker/</guid>
      <description>

&lt;p&gt;Esse tutorial é sobre a construção do pacote do Hadoop 2.7.1 para o CentOS6 / RHEL6 usando Docker. Esse procedimento é necessário para gerar as bibliotecas nativas compatíveis. O principal objetivo que motivou esse trabalho foi configurar o FairScheduler do YARN usando CGroups rodando no Red Hat Enterprise Linux 6 (RHEL6). O pacote Hadoop distribuído pela Apache tem executável binário que não é compatível com a Glibc que faz parte do CentOS6/RHEL6.&lt;/p&gt;

&lt;p&gt;O RHEL6 é o sistema operacional homologado para as máquinas do cluster que usamos na Globo.com e foi necessário criar uma distribuição própria do Hadoop para que pudéssemos fazer uso do &lt;a href=&#34;http://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/FairScheduler.html&#34;&gt;FairScheduler&lt;/a&gt; juntamente com o &lt;a href=&#34;http://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/NodeManagerCgroups.html&#34;&gt;CGroups&lt;/a&gt; para limitar o uso de processamento entre as aplicações rodando nos mesmos NodeManagers.&lt;/p&gt;

&lt;p&gt;Esse trabalho de configuração do Hadoop para uso compartilhado será assunto de outro artigo.&lt;/p&gt;

&lt;p&gt;Nesse artigo, o foco é um passo a passo de como usar o Docker para gerar um pacote do Hadoop adaptado para o Red Hat Enterprise Linux 6 (RHEL6) usando CentOS6.&lt;/p&gt;

&lt;h2 id=&#34;pré-requisito:ac8d87b01c866329a85ac2f7311bc677&#34;&gt;Pré-requisito&lt;/h2&gt;

&lt;p&gt;Nesse procedimento, é necessário que o Docker esteja instalado e funcionando; também é necessário acesso à Internet.&lt;/p&gt;

&lt;p&gt;Originalmente, esse procedimento foi testado no ArchLinux atualizado até final de Agosto/2015.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://wiki.archlinux.org/index.php/Docker&#34;&gt;https://wiki.archlinux.org/index.php/Docker&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;sudo docker version

&amp;gt; Client:
&amp;gt;  Version:      1.8.1
&amp;gt;  API version:  1.20
&amp;gt;  Go version:   go1.4.2
&amp;gt;  Git commit:   d12ea79
&amp;gt;  Built:        Sat Aug 15 17:29:10 UTC 2015
&amp;gt;  OS/Arch:      linux/amd64
&amp;gt;
&amp;gt; Server:
&amp;gt;  Version:      1.8.1
&amp;gt;  API version:  1.20
&amp;gt;  Go version:   go1.4.2
&amp;gt;  Git commit:   d12ea79
&amp;gt;  Built:        Sat Aug 15 17:29:10 UTC 2015
&amp;gt;  OS/Arch:      linux/amd64&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;h2 id=&#34;compilação:ac8d87b01c866329a85ac2f7311bc677&#34;&gt;Compilação&lt;/h2&gt;

&lt;p&gt;Documento com instruções de build do Hadoop &lt;a href=&#34;https://github.com/apache/hadoop/blob/release-2.7.1/BUILDING.txt&#34;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;O resultado desse procedimento é um pacote do Hadoop com os executáveis e bibliotecas nativas compilados para o CentOS6 que rodam no RHEL6.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;Começamos com a criação de um conainer do Docker com a imagem do CentOS6.&lt;/p&gt;

&lt;p&gt;Ao executar o comando &lt;code&gt;run&lt;/code&gt;, o Docker automaticamente fará o download da imagem e a shell será inicializada dentro de um novo container.&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;sudo docker run -i -t centos:6 /bin/bash

&amp;gt; Unable to find image &amp;#39;centos:6&amp;#39; locally
&amp;gt; 6: Pulling from library/centos
&amp;gt;
&amp;gt; f1b10cd84249: Pull complete
&amp;gt; fb9cc58bde0c: Pull complete
&amp;gt; a005304e4e74: Already exists
&amp;gt; library/centos:6: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security.
&amp;gt;
&amp;gt; Digest: sha256:25d94c55b37cb7a33ad706d5f440e36376fec20f59e57d16fe02c64698b531c1
&amp;gt; Status: Downloaded newer image for centos:6
&amp;gt; [root@3cc2bc5e593b /]#&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;Já dentro do container criamos um usuário e local que serão usados na compilação e geração do pacote.&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;adduser -m -d /hadoop hadoop
cd hadoop&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;Para a compilação das bibliotecas nativas é necessária a instalação do compilador C e mais alguns pacotes de desenvolvimento (cabeçalhos das bibliotecas usadas pelo Hadoop).&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;yum install -y tar gzip gcc-c&amp;#43;&amp;#43; cmake zlib zlib-devel openssl openssl-devel fuse fuse-devel bzip2 bzip2-devel snappy snappy-devel

&amp;gt; (...)&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;O Hadoop ainda depende de duas outras bibliotecas que precisam ser instaladas manualmente no CentOS: Google ProtoBuf 2.5 (RPC), Jansson (JSON).&lt;/p&gt;

&lt;p&gt;Para instalar o ProtoBuf, é necessário baixar o pacote, configurar para as pastas do CentOS (64 bits) e instalar.&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;curl -L -O https://github.com/google/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz
tar zxf protobuf-2.5.0.tar.gz
cd protobuf-2.5.0
./configure --prefix=/usr --libdir=/usr/lib64
make
make check
make install

cd ..&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;Para instalar o Jansson, é necessário baixar o pacote, configurar para as pastas do CentOS (64 bits) e instalar.&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;curl -O http://www.digip.org/jansson/releases/jansson-2.7.tar.gz
tar zxf jansson-2.7.tar.gz
cd jansson-2.7
./configure --prefix=/usr --libdir=/usr/lib64
make
make install

cd ..&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;Para completar o ambiente de compilação, precisamos do JDK e do Maven.&lt;/p&gt;

&lt;p&gt;No caso do JDK, usaremos o pacote RPM já disponibilizado pela Oracle.&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;curl -k -L -H &amp;#34;Cookie: oraclelicense=accept-securebackup-cookie&amp;#34; -O http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.rpm
rpm -i jdk-8u60-linux-x64.rpm&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;No caso do Maven, usaremos o pacote binário de distribuição da Apache.&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;curl -O http://archive.apache.org/dist/maven/maven-3/3.3.3/binaries/apache-maven-3.3.3-bin.tar.gz
tar zxf apache-maven-3.3.3-bin.tar.gz&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;O ambiente  de compilação está completo.&lt;/p&gt;

&lt;p&gt;Agora estamos pronto para a compilação do Hadoop. Nesse caso, estaremos gerando o pacote de distribuição somente com o binário Java e as bibliotecas nativas.&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;su - hadoop

export PATH=$PATH:/hadoop/apache-maven-3.3.3/bin

curl -O http://archive.apache.org/dist/hadoop/common/hadoop-2.7.1/hadoop-2.7.1-src.tar.gz
tar zxf hadoop-2.7.1-src.tar.gz
cd hadoop-2.7.1-src

mvn clean package -Pdist,native -DskipTests -Drequire.snappy -Drequire.openssl -Dtar

&amp;gt; (...)
&amp;gt; main:
&amp;gt;      [exec] $ tar cf hadoop-2.7.1.tar hadoop-2.7.1
&amp;gt;      [exec] $ gzip -f hadoop-2.7.1.tar
&amp;gt;      [exec]
&amp;gt;      [exec] Hadoop dist tar available at: /hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz
&amp;gt;      [exec]
&amp;gt; [INFO] Executed tasks
&amp;gt; [INFO]
&amp;gt; [INFO] --- maven-javadoc-plugin:2.8.1:jar (module-javadocs) @ hadoop-dist ---
&amp;gt; [INFO] Building jar: /hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-dist-2.7.1-javadoc.jar
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] Reactor Summary:
&amp;gt; [INFO]
&amp;gt; [INFO] Apache Hadoop Main ................................. SUCCESS [01:56 min]
&amp;gt; [INFO] Apache Hadoop Project POM .......................... SUCCESS [ 42.134 s]
&amp;gt; [INFO] Apache Hadoop Annotations .......................... SUCCESS [ 37.761 s]
&amp;gt; [INFO] Apache Hadoop Assemblies ........................... SUCCESS [  0.125 s]
&amp;gt; [INFO] Apache Hadoop Project Dist POM ..................... SUCCESS [ 23.183 s]
&amp;gt; [INFO] Apache Hadoop Maven Plugins ........................ SUCCESS [ 25.962 s]
&amp;gt; [INFO] Apache Hadoop MiniKDC .............................. SUCCESS [03:23 min]
&amp;gt; [INFO] Apache Hadoop Auth ................................. SUCCESS [02:11 min]
&amp;gt; [INFO] Apache Hadoop Auth Examples ........................ SUCCESS [ 10.145 s]
&amp;gt; [INFO] Apache Hadoop Common ............................... SUCCESS [03:29 min]
&amp;gt; [INFO] Apache Hadoop NFS .................................. SUCCESS [  4.724 s]
&amp;gt; [INFO] Apache Hadoop KMS .................................. SUCCESS [02:35 min]
&amp;gt; [INFO] Apache Hadoop Common Project ....................... SUCCESS [  0.024 s]
&amp;gt; [INFO] Apache Hadoop HDFS ................................. SUCCESS [02:15 min]
&amp;gt; [INFO] Apache Hadoop HttpFS ............................... SUCCESS [02:13 min]
&amp;gt; [INFO] Apache Hadoop HDFS BookKeeper Journal .............. SUCCESS [ 38.598 s]
&amp;gt; [INFO] Apache Hadoop HDFS-NFS ............................. SUCCESS [  3.213 s]
&amp;gt; [INFO] Apache Hadoop HDFS Project ......................... SUCCESS [  0.032 s]
&amp;gt; [INFO] hadoop-yarn ........................................ SUCCESS [  0.030 s]
&amp;gt; [INFO] hadoop-yarn-api .................................... SUCCESS [ 29.193 s]
&amp;gt; [INFO] hadoop-yarn-common ................................. SUCCESS [02:02 min]
&amp;gt; [INFO] hadoop-yarn-server ................................. SUCCESS [  0.040 s]
&amp;gt; [INFO] hadoop-yarn-server-common .......................... SUCCESS [  8.499 s]
&amp;gt; [INFO] hadoop-yarn-server-nodemanager ..................... SUCCESS [ 12.283 s]
&amp;gt; [INFO] hadoop-yarn-server-web-proxy ....................... SUCCESS [  2.359 s]
&amp;gt; [INFO] hadoop-yarn-server-applicationhistoryservice ....... SUCCESS [  5.298 s]
&amp;gt; [INFO] hadoop-yarn-server-resourcemanager ................. SUCCESS [ 15.095 s]
&amp;gt; [INFO] hadoop-yarn-server-tests ........................... SUCCESS [  3.772 s]
&amp;gt; [INFO] hadoop-yarn-client ................................. SUCCESS [  4.641 s]
&amp;gt; [INFO] hadoop-yarn-server-sharedcachemanager .............. SUCCESS [  2.433 s]
&amp;gt; [INFO] hadoop-yarn-applications ........................... SUCCESS [  0.019 s]
&amp;gt; [INFO] hadoop-yarn-applications-distributedshell .......... SUCCESS [  1.884 s]
&amp;gt; [INFO] hadoop-yarn-applications-unmanaged-am-launcher ..... SUCCESS [  1.263 s]
&amp;gt; [INFO] hadoop-yarn-site ................................... SUCCESS [  0.020 s]
&amp;gt; [INFO] hadoop-yarn-registry ............................... SUCCESS [  3.532 s]
&amp;gt; [INFO] hadoop-yarn-project ................................ SUCCESS [  3.452 s]
&amp;gt; [INFO] hadoop-mapreduce-client ............................ SUCCESS [  0.036 s]
&amp;gt; [INFO] hadoop-mapreduce-client-core ....................... SUCCESS [ 15.195 s]
&amp;gt; [INFO] hadoop-mapreduce-client-common ..................... SUCCESS [ 12.459 s]
&amp;gt; [INFO] hadoop-mapreduce-client-shuffle .................... SUCCESS [  2.645 s]
&amp;gt; [INFO] hadoop-mapreduce-client-app ........................ SUCCESS [  6.342 s]
&amp;gt; [INFO] hadoop-mapreduce-client-hs ......................... SUCCESS [  3.845 s]
&amp;gt; [INFO] hadoop-mapreduce-client-jobclient .................. SUCCESS [ 11.295 s]
&amp;gt; [INFO] hadoop-mapreduce-client-hs-plugins ................. SUCCESS [  1.546 s]
&amp;gt; [INFO] Apache Hadoop MapReduce Examples ................... SUCCESS [  4.573 s]
&amp;gt; [INFO] hadoop-mapreduce ................................... SUCCESS [  2.164 s]
&amp;gt; [INFO] Apache Hadoop MapReduce Streaming .................. SUCCESS [  7.874 s]
&amp;gt; [INFO] Apache Hadoop Distributed Copy ..................... SUCCESS [ 19.660 s]
&amp;gt; [INFO] Apache Hadoop Archives ............................. SUCCESS [  2.071 s]
&amp;gt; [INFO] Apache Hadoop Rumen ................................ SUCCESS [  3.966 s]
&amp;gt; [INFO] Apache Hadoop Gridmix .............................. SUCCESS [  3.215 s]
&amp;gt; [INFO] Apache Hadoop Data Join ............................ SUCCESS [  1.818 s]
&amp;gt; [INFO] Apache Hadoop Ant Tasks ............................ SUCCESS [  1.478 s]
&amp;gt; [INFO] Apache Hadoop Extras ............................... SUCCESS [  2.037 s]
&amp;gt; [INFO] Apache Hadoop Pipes ................................ SUCCESS [  5.880 s]
&amp;gt; [INFO] Apache Hadoop OpenStack support .................... SUCCESS [  3.407 s]
&amp;gt; [INFO] Apache Hadoop Amazon Web Services support .......... SUCCESS [ 40.013 s]
&amp;gt; [INFO] Apache Hadoop Azure support ........................ SUCCESS [ 11.557 s]
&amp;gt; [INFO] Apache Hadoop Client ............................... SUCCESS [  7.659 s]
&amp;gt; [INFO] Apache Hadoop Mini-Cluster ......................... SUCCESS [  0.042 s]
&amp;gt; [INFO] Apache Hadoop Scheduler Load Simulator ............. SUCCESS [  3.072 s]
&amp;gt; [INFO] Apache Hadoop Tools Dist ........................... SUCCESS [  8.519 s]
&amp;gt; [INFO] Apache Hadoop Tools ................................ SUCCESS [  0.014 s]
&amp;gt; [INFO] Apache Hadoop Distribution ......................... SUCCESS [ 30.616 s]
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] BUILD SUCCESS
&amp;gt; [INFO] ------------------------------------------------------------------------
&amp;gt; [INFO] Total time: 29:26 min
&amp;gt; [INFO] Finished at: 2015-09-01T00:47:31&amp;#43;00:00
&amp;gt; [INFO] Final Memory: 224M/785M
&amp;gt; [INFO] ------------------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;Para completar a compilação, executamos os testes, contudo, alguns deles podem apresentar falhas intermitentes (acontecem algumas vezes, outras não).&lt;/p&gt;

&lt;p&gt;Os testes podem levar algumas horas para rodar por completo.&lt;/p&gt;

&lt;p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34; style=&#34;font-size: medium; line-height: 1.2;&#34;&gt;mkdir hadoop-common-project/hadoop-common/target/test-classes/webapps/test

mvn test -Pnative -Drequire.snappy -Drequire.openssl -Dmaven.test.failure.ignore=true -Dsurefire.rerunFailingTestsCount=3

&amp;gt; (...)&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;(alguns testes com falha intermitente)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;org.apache.hadoop.ipc.TestDecayRpcScheduler#testAccumulate&lt;/li&gt;
&lt;li&gt;org.apache.hadoop.ipc.TestDecayRpcScheduler#testPriority&lt;/li&gt;
&lt;li&gt;org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetrics#testDataNodeTimeSpend&lt;/li&gt;
&lt;li&gt;org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitCache#testDataXceiverHandlesRequestShortCircuitShmFailure&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;No final desse procedimento, o pacote do Hadoop estará gerado em:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;/hadoop/hadoop-2.7.1-src/hadoop-dist/target/hadoop-2.7.1.tar.gz&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusão:ac8d87b01c866329a85ac2f7311bc677&#34;&gt;Conclusão&lt;/h2&gt;

&lt;p&gt;Esse procedimento mostra como o Hadoop pode ser customizado para necessidades específicas e que não requer um esforço muito grande.&lt;/p&gt;

&lt;p&gt;Contudo, ter uma &amp;ldquo;versão&amp;rdquo; própria do Hadoop é uma decisão que deve ser tomada com cautela.&lt;/p&gt;

&lt;p&gt;No momento, a gente considera que essa seja a melhor escolha para o nosso trabalho na Globo.com e estamos querendo formar um time para evoluir e dar suporte a essa plataforma. O maior benefício é a liberdade de escolher como configurar e melhorar nossa infraestrutura. O custo é não ter uma empresa especializada &amp;ldquo;cuidando&amp;rdquo; dessa responsabilidade.&lt;/p&gt;

&lt;p&gt;No futuro, pode ser que mudemos esse modo de operação e busquemos uma distribuição &amp;ldquo;profissional&amp;rdquo; como Cloudera, Hortonworks ou outra.&lt;/p&gt;

&lt;p&gt;Particularmente, eu prefiro manter uma plataforma própria.&lt;/p&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;p&gt;Você trabalha com Hadoop ou tem experiência com as tecnologias envolvidas (Java)? Venha trabalhar conosco.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://talentos.globo.com/&#34;&gt;http://talentos.globo.com/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>